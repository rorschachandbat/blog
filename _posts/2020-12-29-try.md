---
title: try
layout: post
---
[toc]

## 绪论

### 分类

1. 屈折语(fusional language/inflectional language):
   用词的形态变化表示语法关系，如英语、法语等。
2. 黏着语(agglutinative language): 词内有专门表示
   语法意义的附加成分，词根或词干与附加成分的结合
   不紧密，如日语、韩语、土耳其语等。
3. 孤立语/分析语(isolating / analytic language): 形态
   变化少，语法关系靠词序和虚词表示，如汉语。

### 基本问题

#### 形态学

单词的识别 / 汉语的分词问题。

#### 语法学

为什么一句话可以这么说，也可以那么说？

#### 语义学

这句话说了什么？

#### 语用学

为什么要说这句话？

### 困难

#### 大量歧义

词法、文章标题、词性、结构、语义、语音

#### 大量未知语言现象

新词、新含义、新用法、新句型

### 基本研究方法

经验主义方法

理性主义方法

## 数学基础

### 概率论基础

#### 概率

#### 最大似然估计

用频率估计概率

#### 条件概率

![image-20201227130302395](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201227130302395.png)

#### 全概率公式

![image-20201227130442245](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201227130442245.png)

#### 贝叶斯法则

![image-20201227130505490](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201227130505490.png)

## 形式语言与自动机

### 基本概念

#### 树

连通的的无回路的无向图

#### 字符串

##### 操作（要把字符串看成一个集合，操作也是要对集合里的每一个都操作）

连接、乘积、闭包

闭包中，V*包括空集，V+不包括

例：𝑉 = {𝑎, 𝑏} 𝑉 ∗ = {𝜀, 𝑎, 𝑏, 𝑎𝑎, 𝑎𝑏, 𝑏𝑏, 𝑏𝑎, 𝑎𝑎𝑎, … } 𝑉 + = {𝑎, 𝑏, 𝑎𝑎, 𝑎𝑏, 𝑏𝑎, 𝑏𝑏, 𝑎𝑎𝑎, … }

##### 正则表达式

组合各种操作

### 形式语言

#### 产生方式

穷举法：只适合句子数目有限的语言。

语法描述：生成语言中合格的句子。

自动机：对输入的句子进行检验，区别哪些是语言中的句子，哪些不是语言中的句子。

#### 定义

𝐺 = (𝑁, Σ, 𝑃, 𝑆)

其中 𝑁 是非终结符的有限集合(有时也叫变量集或句法种类集)；Σ 是 终结符的有限集合，𝑁 ∩ Σ = Φ；𝑉 = 𝑁 ∪ Σ 称为总词汇表；𝑃 是一组重写规则的有限集合：𝑃 = 𝛼 → 𝛽 ， 其中，𝛼，𝛽 是 𝑉 中元素构成的串，但 𝛼 中至少应含有 一个非终结符号；𝑆 ∈ 𝑁，称为句子符或初始符。

约定每步推导中只改写最左边的那个非终结符，这种推导称为“最左推导” 。约定每步推导中只改写最右边的那个非终结符，这种 推导称为“最右推导” 。最右推导也称规范推导。

#### 文法定义

##### 正则文法（3型）

𝐴 → 𝐵𝑥，或 𝐴 → 𝑥，其中 𝐴, 𝐵 ∈ 𝑁， 𝑥 ∈ Σ（左线性正则）

𝐴 → 𝑥𝐵（右线性正则文法）

##### 上下文无关（2型）

𝐴 → 𝛼，其中 𝐴 ∈ 𝑁，𝛼 ∈ (𝑁 ∪ Σ)* 

##### 上下文有关文法（1型）

if 𝑥 → 𝑦, 𝑥 ∈ (𝑁 ∪ Σ) + , 𝑦 ∈ (𝑁 ∪ Σ) ∗ 并且 𝑦 ≥ 𝑥 。

##### 无约束文法（0型）

𝛼 → 𝛽，𝛼，𝛽 是字符串

### 自动机

![image-20201227134119998](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201227134119998.png)

#### 确定性有限自动机(definite automata, DFA)

确定的有限自动机 𝑀 是一个五元组： 𝑀 = (Σ,𝑄, 𝛿, 𝑞0, 𝐹)

Σ 是输入符号的有穷集合； 𝑄 是状态的有限集合； 𝑞0 ∈ 𝑄 是初始状态； 𝐹 是终止状态集合，𝐹 ⊆ 𝑄； 𝛿 是 𝑄 与 Σ 的直积 𝑄 × Σ 到 𝑄 (下一个状态) 的映射， 支配着有限状态控制的行为，有时也称为状态转移函数。

#### 不确定性有限自动机 (non-definite automata, NFA)

不确定性有限自动机 𝑀 是一个五元组： 𝑀 = (Σ,𝑄, 𝛿, 𝑞0, 𝐹)

其中， Σ 是输入符号的有穷集合； 𝑄 是状态的有限集合； 𝑞0 ∈ 𝑄 是初始状态； 𝐹 是终止状态集合，𝐹 ⊆ 𝑄； 𝛿 是 𝑄 与 Σ 的直积 𝑄 × Σ 到 𝑄 的幂集 2 𝑄 的映射。

#### 自动机与正则文法

**一个正则文法对应了一个自动机**

**产生步骤**

① 令 Σ = 𝑉𝑇, 𝑄 = 𝑉𝑁 ∪ 𝑇 ，𝑞0 = 𝑆，其中，𝑇 是一个新增加的非终结符。
② 如果在 𝑃 中有产生式 𝑆 → 𝜀，则 𝐹 = {𝑆, 𝑇}，否则𝐹 = {𝑇}。
③ 如果在 𝑃 中有产生式 𝐵 → 𝑎，𝐵 ∈ 𝑉𝑁，𝑎 ∈ 𝑉𝑇，则𝑇 ∈ 𝛿(𝐵, 𝑎)。
④ 如果在 𝑃 中有产生式 𝐵 → 𝑎𝐶，𝐵, 𝐶 ∈ 𝑉𝑁，𝑎 ∈ 𝑉𝑇，则 𝐶 ∈ 𝛿(𝐵, 𝑎)。
⑤ 对于每一个 𝑎 ∈ 𝑉𝑇 ， 有 𝛿 𝑇, 𝑎 = ∅。

#### 下推自动机 (push-down automata, PDA)（待补）

#### 图灵机和线性带限自动机（待补）

#### 自动机和拼写检查

## 语料库与语言知识库

### 基本概念

语料库(corpus)就是存放语言材料的仓库(语言数据库)。

### 分类

#### 按内容和目的

**异质的 (heterogeneous)**

最简单的语料收集方法，没有事先规定和选材原则。

**同质的(homogeneous)**

与“异质”正好相反，比如美国的 TIPSTER 项目只收集军事方面的文本。

**系统的(systematic)** 

充分考虑语料的动态和静态问题、代表性和平衡问题 以及语料库的规模等问题。

**专用的(specialized)** 

如：北美的人文科学语料库。

#### 按语言种类

单语的
双语的或多语的
篇章对齐 / 句子对齐 / 结构对齐

#### 是否标注

—具有词性标注
—句法结构信息标注(树库)
—语义信息标注

#### 平衡语料库与平行语料库

**平衡**

语料的真实性、可靠性、科学 性、代表性、权威性、分布性和流通性。其中，语料 的分布性还要考虑语料的科学领域分布、地域分布、 时间分布和语体分布等。

**平行**

一种是指在同一种语言的语料上的平行。 例如“国际英语语料库” ，共有20个平行的子语料库， 分别来自以英语为母语或官方语言和主要语言的国家， 如英国、美国、加拿大、澳大利亚、新西兰等。

另一种平行语料库是指在两种或多种语言 之间的平行采样和加工。

#### 共时语料库与历时语料库

**共时**

为了对语言进行共时(同一时段)研究而 建立的语料库。共时研究是指研究大树的横断面所见 的细胞和细胞关系， 即研究一个共时平面中的元素与元素的关系

**历时**

为了对语言进行历时研究而建立的语料库。历时研究是研究大树的纵剖面所见的每个细胞和细胞关系的演变，即研究一个历时切面中元素与元素关系的演化。

(1) 是否动态语料库：语料库必须是开放的、动态的。
(2) 文本是否具有量化的流通度属性：所有的语料都应来源于大众传媒，具有与传媒特色相应的流通度属性。其量化的属性值也是动态的。
(3) 深加工是否基于动态的加工方法：随语料的动态变化采集，并进行动态地加工。
(4) 是否取得动态的加工结果：语料的加工结果也应是动态的和历时的。

### 词汇知识库

记录词汇之间的相互关系

## 语言模型

### 基本概念

#### 如何计算一段文字的概率？

![image-20201227152841728](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201227152841728.png)

### 参数估计

➢ 训练语料(training data)：用于建立模型，确定模型参数的已知语料。 

➢ 最大似然估计(maximum likelihood Evaluation, MLE)：用相对频率计算概率的方法。

### 数据平滑

因为数据量可能会少，所以需要调整最大似然估计的概率值，使零概率增值，使非零概率下调，增大整体正确率

目标：测试样本的语言模型困惑度越小越好。

约束：概率加起来等于1

#### 加一法

#### 减值法

➢ Good-Turing法：对非0事件按公式削减出现的次数，余留出来的概率均分给0概率事件。
➢ Katz后退法：对非0事件按Good-Turing法计算减值，余留出来的概率按低阶分布分给0概率事件。
➢ 绝对减值法：对非0事件无条件削减某一固定的出现次数值，余留出来的概率均分给0概率事件。
➢ 线性减值法：对非0事件根据出现次数按比例削减次数值，余留出来的概率均分给0概率事件。

#### 删除插值法 (Deleted Interpolation)：

#### 删值插值法

用低阶语法估计高阶语法，即当3-gram的 值不能从训练数据中准确估计时，用2-gram来替代，同 样，当2-gram的值不能从训练语料中准确估计时，可以 用1-gram的值来代替。插值公式

### 语言模型的自适应

#### 基于缓存的语言模型 (cache-based LM)

文本中刚刚出现过的一些词在后边的句 子中再次出现的可能性往往较大

#### 基于混合方法的语言模型

训练语料是异源的，而测试语料一般是同源的(homogeneous)， 因此，为了获得最佳性能，语言模型必须适应各种不同 类型的语料对其性能的影响

将语言模型划分成𝑛个子模型𝑀1, 𝑀2, ⋯ ,𝑀𝑛，整个语言模型的概率通过下面的线性插 值公式计算得到

插值会用

![image-20201229160533005](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229160533005.png)

#### 基于最大熵的语言模型

通过结合不同信息源的信息构建一个语言模型。每个信息源提供一组关于模型参数的约束条件， 在所有满足约束的模型中，选择熵最大的模型。

### 神经网络模型

基于前馈神经网络的模型直观上看就是使用神经网络 编码的n-gram模型，也无法解决长期依赖的问题。

**改进**

➢ 为了解决定长信息的问题，Mikolov于2010年提出利用循环神经网络(Recurrent Neural Network, RNN) 建立语言模型。 

➢ 使用了RNN中的隐状态来记录词序的历史信息，能够捕获语言中的长程依赖。

## 隐马尔科夫模型

### 马尔可夫模型

![image-20201229163228204](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229163228204.png)

类似动态规划

如果时间t的状态只与t-1的状态相关，则该系统构成一个离散的**一阶马尔科夫链**

如果不考虑时间，则称为马尔科夫模型

![image-20201229163549947](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229163549947.png)

### 隐马尔可夫模型

双重随机过程， 不知道状态序列，只知道状态转移概率，即只知道状态产生结果的概率，但不知道状态的序列

![image-20201229163833258](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229163833258.png)

![](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229164104367.png)

![image-20201229164117297](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229164117297.png)

## 词法分析与词性标注

### 概述

自动词法分析就是利用计算机对自然语言的形态 (morphology) 进行分析，判断词的结构和类别等。

#### 分析语（汉语）

一般不是通过词形变化 （即词的内部形态变化，又称作屈折变化）来表达语法 的作用，而是通过独立的虚词和固定的词序来表达语法意义

分词

#### 曲折语（英语、德语）

用词的形态变化 表示语法关系，一个形态成分可以表示若干种不同的语 法意义，词根和词干与语词的附加成分结合紧密。

词的形态分析（形态还原）

#### 黏着语（日语）

通过在词根的前中后粘贴不同的词尾来实现语法功能。

分词+形态还原

### 英语的形态分析

(1) 查词典，如果词典中有该词，直接确定该词的原形； 

(2) 根据不同情况查找相应规则对单词进行还原处理， 如果还原后在词典中找到该词，则得到该词的原形； 如果找不到相应变换规则或者变换后词典中仍查不到 该词，则作为未登录词处理； 

(3) 进入未登录词处理模块。

### 汉语自动分词

#### 主要问题

**分词规范**

单字词、词与短语

**歧义切分字段处理**

**未登录词的识别**

#### 基本原则

1. **语义**上无法由组合成分直接相加而得到的字串应该合并为一个分词单位。
2. **语类**无法由组合成分直接得到的字串应该合并为一个分词单位。

#### 辅助原则

1. 有明显分隔符标记的应该切分之
2. 附着性语(词)素和前后词合并为一个分词单位
3. 使用频率高或共现率高的字串尽量合并为一个分词单位
4. 双音节加单音节的偏正式名词尽量合并为一个分词单位
5. 双音节结构的偏正式动词应尽量合并为一个分词单位
6. 内部结构复杂、合并起来过于冗长的词尽量切分

### 分词与词性标注结果评价

#### 评价标准

**正确率**

测试结果中正确切分或标注的个数占系统所有输出结果的比例。

**召回率**

测试结果中正确结果的个数占标准答案总数的比例

F-测度值(F-Measure)

![image-20201229170248737](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229170248737.png)

![image-20201229170510608](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229170510608.png)

![image-20201229170529451](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229170529451.png)

### 汉语自动分词基本算法

#### 最大匹配法

##### 正向最大匹配法（FMM）

从左到右取m个字符（m是字典里的最大字符数），如果成功则去除这m个字符，若不成功则将字符串最后一个字符去掉并重新匹配，重复上述过程直到切分出所有词为止。

##### 逆向最大匹配法（BMM）

##### 双向最大匹配法（MM）

➢ 优点：
• 程序简单易行，开发周期短；
• 仅需要很少的语言资源（词表），不需要任何词法、句法、语义资源；
➢ 弱点：
• 歧义消解的能力差；
• 切分正确率不高，一般在95％左右。

#### N-最短路径法 (最少分词法)

给定一待处理字串，根据词典，找出词典中所有可能 的词，构造出字串的一个有向无环图，算出从开始到结 束所有路径中最短的前N条路径。 因为允许相等长度的路径并列，故最终的结果集合会 大于或等于N

算法概述：先用字典生成一个词的无环图，再找出这个图的最短路径

![image-20201229183234023](https://gitee.com/jiang_liyong/cloudimage/raw/master/img/image-20201229183234023.png)

#### 基于语言模型的分词方法

➢ 优点：
• 减少了很多手工标注的工作；
• 在训练语料规模足够大和覆盖领域足够多时，可以
获得较高的切分正确率。
➢ 弱点：
• 训练语料的规模和覆盖领域不好把握；
• 计算量较大。

#### 基于HMM的分词方法

➢ 优点：
• 可以减少很多手工标注的工作量；
• 在训练语料规模足够大和覆盖领域足够多时，可以
获得较高的切分正确率。
➢ 弱点：
• 训练语料的规模和覆盖领域不好把握；
• 模型实现复杂、计算量较大。

#### 由字构词(基于字标注)的分词方法